# verify-audit-trail #

This utility takes an audit trail generated by a vote3fe frontend and verifies that it meets some fundamental consistency properties. In particular, it verifies:

 * That the server asserts that there are a particular number of entries, and that the number of entries match the assertion.
 * That all the digital signatures on the entries verify.
 * The hash chain verifies.

It also prints out timing information from the signatures, so you can check that voting happened in the expected time period and not before or after.

*VAT does **not** require a local installation vote3 - you can verify an audit trail without installing anything.* It runs without any external dependencies, and on Python 2 or 3. Verify an election today!

## Verifying an audit trail ##

You can verify an audit trail with `vat.py`.

It will attempt to use the system's GPG. If GPG isn't found (maybe you are on Windows?) it'll just skip verifying the signatures.

To run it, go:

`vat.py http://server/vote/audit`

where `server` is the address of the server running the election.

It will complain if you have GPG but don't have a copy of the Vote3 signing key locally: ask your friendly returning officer how to get it. (You don't get a copy when you download this because it's generated at random each time Vote3 is installed, otherwise it would be of no security value.)

## What verification does and does not prove ##

Verification protects you against two things.

Firstly and primarily, it protects you against inadvertent programming errors in the Vote3 system and in vote counting systems by providing you with enough information to reconstruct the vote database and verify the vote count. In this capacity, the hashes and signatures are simply a way to be more certain that the operations occurred in the order specified.

Secondly, it protects you against a monkey-in-the-middle attack - an attacker who sits on the network in between you and the vote3 server has no ability to carry out undetetable attacks.

The audit trail should not be considered to provide protection against an untrustworthy administrator, or anyone who has a copy of the Vote3 private signing key. The properties of the system make pulling off an attack as a malicious administrator harder (or at least easier to detect) although this is not its primary purpose.

### How am I protected against a MITM attack?

Verification proves that the attacker without access to the signing key cannot:

 * Add an entry
 * Remove an entry
 * Modify an entry
 * Make an undetectable change to a vote in transit.

An attacker with access to the signing key (e.g. a malicious administrator) can in theory do any of those three things, but they have a higher chance of being detected.

We assume that the voter/verifier has a clean copy of the Vote3 signing key. 

We consider an attacker with active MITM (monkey in the middle) capabilities, and show that any of the 4 attacks (except removing the final message) require one or more of the following underlying attacks:

 - forging a PGP signature
 - forging multiple PGP signatures
 - finding a SHA-384 pre-image for a given hash
 - finding a SHA-384 collision for a given hash

Consider adding an entry. Here we assume the attacker notices that the audit trail is being downloaded, and replaces the true audit trail with an audit trail of their own:

 * Adding an entry at the end is the easiest. An attacker calculates the SHA384 of the previous message, then writes their own message. However, they have to forge a PGP signature from the Vote3 signing key.
 * Adding a message mid-stream is harder. There are two possibilities:
     * Create an arbitrary message and sign it. This will cause the hash to fail in the subsequent message, so every subsequent message will need to be modified and resigned. This means that the attacker must forge multiple PGP signatures.
     * Create a message such that it matches the expected hash. This requires a pre-image attack on SHA-384 and the forging of a signature.

Consider modifying an entry:
 * The attacker must forge a PGP signature.
 * If modifying a midstream message, the attacker must either:
     * modify every subsequent message and forge their signatures too, or
     * find a collision on the SHA-384 hash such that their modified message has the same hash as the original.

Consider removing an entry:
 * The final entry can be removed undetected. (This is why closing an election before counting it is important, as that provides an 'election closed' message that can be checked for, and which has the hash of the final vote.)

 * If you add an entry mid stream, 

 * If you try to hide or omit an entry from the middle of the audit trail, it will probably be detected: Say you delete entry 7 by moving all the other entries forward, so 8 becomes 7, 9 becomes 8, etc.
     * The hash on 8 will need to be changed, then the hash on 9, etc.
     * Therefore entry 8 and following will all need to be resigned - the attacker needs the key
     * Say the attacker has the key. They will suceed in making an undetected change only if no-one with an audit trail message that comes after the change (e.g. the voter for entry 9) can come forward and show that the audit trail has changed and their hash is no longer part of the chain.
         * This is obviously not foolproof. I'm thinking through better ways to do this.

 * 
   


### Things that could one day be proven but are not


### Things that will never be proven
This is not a comprehensive list.

 * That the RO didn't keep votecodes to him/herself and use them to vote in the election.
 * That the audit trail hasn't been truncated. (Will be mitigated by the presence of an 'voting closed' entry in the future.)
